import logging
import requests
from pathlib import Path
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


class WordAPI:
    def __init__(self, word_api_url=None, sentence_api_url=None):
        """
        åˆå§‹åŒ–æ¯æ—¥å•è¯APIå®¢æˆ·ç«¯
        
        å‚æ•°:
        - word_api_url: æ¯æ—¥å•è¯APIåœ°å€
        - sentence_api_url: æ¯æ—¥é•¿å¥APIåœ°å€
        """
        # ä½¿ç”¨å…è´¹çš„æ¯æ—¥å•è¯API
        self.word_api_url = word_api_url or "https://api.wordnik.com/v4/words.json/wordOfTheDay"
        self.sentence_api_url = sentence_api_url or "https://api.quotable.io/random"
        
        # æ•°æ®å­˜å‚¨è·¯å¾„
        self.data_dir = Path(__file__).parent.parent / 'data'
        self.word_file = self.data_dir / 'daily_word.json'
        self.sentence_file = self.data_dir / 'daily_sentence.json'
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self.data_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–å•è¯å’Œå¥å­å±æ€§
        self.word = None
        self.word_definition = None
        self.word_pronunciation = None
        self.word_example = None
        self.sentence = None
        self.sentence_author = None
        self.sentence_tags = None

    def get_daily_word(self):
        """
        è·å–æ¯æ—¥å•è¯åŠå…¶è¯¦ç»†ä¿¡æ¯
        
        è¿”å›:
        - bool: Trueè¡¨ç¤ºæˆåŠŸè·å–ï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        try:
            # ä½¿ç”¨å¤‡ç”¨API - æ¯æ—¥è‹±è¯­å•è¯
            backup_url = "https://api.dictionaryapi.dev/api/v2/entries/en/hello"  # ç¤ºä¾‹ï¼Œå®é™…å¯æ›¿æ¢ä¸ºæ¯æ—¥å•è¯æœåŠ¡
            
            # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„å•è¯åˆ—è¡¨ä½œä¸ºç¤ºä¾‹
            import random
            words_data = [
                {
                    "word": "serendipity",
                    "definition": "The occurrence and development of events by chance in a happy or beneficial way",
                    "pronunciation": "/ËŒserÉ™nËˆdipÉ™dÄ“/",
                    "example": "A fortunate stroke of serendipity brought the two old friends together."
                },
                {
                    "word": "ephemeral",
                    "definition": "Lasting for a very short time",
                    "pronunciation": "/É™Ëˆfem(É™)rÉ™l/",
                    "example": "The beauty of cherry blossoms is ephemeral, lasting only a few weeks."
                },
                {
                    "word": "mellifluous",
                    "definition": "Sweet or musical; pleasant to hear",
                    "pronunciation": "/mÉ™ËˆlifloÍoÉ™s/",
                    "example": "Her mellifluous voice captivated the entire audience."
                },
                {
                    "word": "ubiquitous",
                    "definition": "Present, appearing, or found everywhere",
                    "pronunciation": "/yoÍoËˆbikwÉ™dÉ™s/",
                    "example": "Smartphones have become ubiquitous in modern society."
                },
                {
                    "word": "perspicacious",
                    "definition": "Having a ready insight into and understanding of things",
                    "pronunciation": "/ËŒpÉ™rspÉ™ËˆkÄSHÉ™s/",
                    "example": "The perspicacious detective quickly solved the complex case."
                }
            ]
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªå•è¯ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥åŸºäºæ—¥æœŸé€‰æ‹©ï¼‰
            import datetime
            today = datetime.date.today()
            word_index = today.toordinal() % len(words_data)
            word_data = words_data[word_index]
            
            # æ›´æ–°ç±»å±æ€§
            self.word = word_data['word']
            self.word_definition = word_data['definition']
            self.word_pronunciation = word_data['pronunciation']
            self.word_example = word_data['example']
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_word_data(word_data)
            
            logging.info(f"æˆåŠŸè·å–æ¯æ—¥å•è¯: {self.word}")
            return True
            
        except Exception as e:
            logging.error(f"è·å–æ¯æ—¥å•è¯æ—¶å‡ºé”™: {e}")
            # å°è¯•ä»æœ¬åœ°æ–‡ä»¶åŠ è½½
            return self._load_word_data()

    def get_daily_sentence(self):
        """
        è·å–æ¯æ—¥åŠ±å¿—é•¿å¥
        
        è¿”å›:
        - bool: Trueè¡¨ç¤ºæˆåŠŸè·å–ï¼ŒFalseè¡¨ç¤ºå¤±è´¥
        """
        try:
            response = requests.get(self.sentence_api_url, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            # æ›´æ–°ç±»å±æ€§
            self.sentence = data.get('content', '')
            self.sentence_author = data.get('author', 'Unknown')
            self.sentence_tags = data.get('tags', [])
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            sentence_data = {
                'sentence': self.sentence,
                'author': self.sentence_author,
                'tags': self.sentence_tags,
                'date': str(datetime.date.today())
            }
            self._save_sentence_data(sentence_data)
            
            logging.info(f"æˆåŠŸè·å–æ¯æ—¥å¥å­: {self.sentence[:50]}...")
            return True
            
        except requests.RequestException as e:
            logging.error(f"è·å–æ¯æ—¥å¥å­æ—¶å‡ºé”™: {e}")
            # å°è¯•ä»æœ¬åœ°æ–‡ä»¶åŠ è½½
            return self._load_sentence_data()
        except Exception as e:
            logging.error(f"å¤„ç†æ¯æ—¥å¥å­æ•°æ®æ—¶å‡ºé”™: {e}")
            return self._load_sentence_data()

    def _save_word_data(self, word_data):
        """ä¿å­˜å•è¯æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            import datetime
            word_data['date'] = str(datetime.date.today())
            with self.word_file.open('w', encoding='utf-8') as f:
                json.dump(word_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜å•è¯æ•°æ®æ—¶å‡ºé”™: {e}")

    def _save_sentence_data(self, sentence_data):
        """ä¿å­˜å¥å­æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with self.sentence_file.open('w', encoding='utf-8') as f:
                json.dump(sentence_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜å¥å­æ•°æ®æ—¶å‡ºé”™: {e}")

    def _load_word_data(self):
        """ä»æ–‡ä»¶åŠ è½½å•è¯æ•°æ®"""
        try:
            if self.word_file.exists():
                with self.word_file.open('r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.word = data.get('word')
                    self.word_definition = data.get('definition')
                    self.word_pronunciation = data.get('pronunciation')
                    self.word_example = data.get('example')
                    logging.info("ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å•è¯æ•°æ®")
                    return True
        except Exception as e:
            logging.error(f"åŠ è½½æœ¬åœ°å•è¯æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

    def _load_sentence_data(self):
        """ä»æ–‡ä»¶åŠ è½½å¥å­æ•°æ®"""
        try:
            if self.sentence_file.exists():
                with self.sentence_file.open('r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.sentence = data.get('sentence')
                    self.sentence_author = data.get('author')
                    self.sentence_tags = data.get('tags', [])
                    logging.info("ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¥å­æ•°æ®")
                    return True
        except Exception as e:
            logging.error(f"åŠ è½½æœ¬åœ°å¥å­æ•°æ®æ—¶å‡ºé”™: {e}")
        return False

    def get_daily_content(self):
        """
        è·å–æ¯æ—¥å®Œæ•´å†…å®¹ï¼ˆå•è¯+å¥å­ï¼‰
        
        è¿”å›:
        - bool: Trueè¡¨ç¤ºè‡³å°‘è·å–äº†ä¸€é¡¹å†…å®¹ï¼ŒFalseè¡¨ç¤ºå…¨éƒ¨å¤±è´¥
        """
        word_success = self.get_daily_word()
        sentence_success = self.get_daily_sentence()
        
        return word_success or sentence_success

    def format_display_content(self):
        """
        æ ¼å¼åŒ–æ˜¾ç¤ºå†…å®¹ï¼Œé€‚åˆå¢¨æ°´å±æ˜¾ç¤º
        
        è¿”å›:
        - str: æ ¼å¼åŒ–åçš„æ˜¾ç¤ºå†…å®¹
        """
        content_lines = []
        
        # æ·»åŠ æ ‡é¢˜
        content_lines.append("=== Daily Word & Quote ===")
        content_lines.append("")
        
        # æ·»åŠ å•è¯éƒ¨åˆ†
        if self.word:
            content_lines.append("ğŸ“š Word of the Day:")
            content_lines.append(f"   {self.word.upper()}")
            if self.word_pronunciation:
                content_lines.append(f"   {self.word_pronunciation}")
            content_lines.append("")
            
            if self.word_definition:
                content_lines.append("Definition:")
                # è‡ªåŠ¨æ¢è¡Œå¤„ç†é•¿å®šä¹‰
                definition_words = self.word_definition.split()
                line = "   "
                for word in definition_words:
                    if len(line + word) > 35:  # é€‚åˆå¢¨æ°´å±çš„è¡Œå®½
                        content_lines.append(line)
                        line = "   " + word + " "
                    else:
                        line += word + " "
                if line.strip():
                    content_lines.append(line)
                content_lines.append("")
            
            if self.word_example:
                content_lines.append("Example:")
                # è‡ªåŠ¨æ¢è¡Œå¤„ç†é•¿ä¾‹å¥
                example_words = self.word_example.split()
                line = "   "
                for word in example_words:
                    if len(line + word) > 35:
                        content_lines.append(line)
                        line = "   " + word + " "
                    else:
                        line += word + " "
                if line.strip():
                    content_lines.append(line)
                content_lines.append("")
        
        # æ·»åŠ åˆ†éš”çº¿
        content_lines.append("-" * 30)
        content_lines.append("")
        
        # æ·»åŠ å¥å­éƒ¨åˆ†
        if self.sentence:
            content_lines.append("ğŸ’­ Quote of the Day:")
            content_lines.append("")
            
            # è‡ªåŠ¨æ¢è¡Œå¤„ç†é•¿å¥å­
            sentence_words = self.sentence.split()
            line = "   \""
            for word in sentence_words:
                if len(line + word) > 33:  # ä¸ºå¼•å·ç•™ç©ºé—´
                    content_lines.append(line)
                    line = "   " + word + " "
                else:
                    line += word + " "
            if line.strip():
                content_lines.append(line.rstrip() + "\"")
            content_lines.append("")
            
            if self.sentence_author:
                content_lines.append(f"   â€” {self.sentence_author}")
                content_lines.append("")
        
        # æ·»åŠ æ—¥æœŸ
        import datetime
        content_lines.append(f"Date: {datetime.date.today().strftime('%Y-%m-%d')}")
        
        return "\n".join(content_lines)

    def get_summary(self):
        """
        è·å–å†…å®¹æ‘˜è¦
        
        è¿”å›:
        - dict: åŒ…å«å•è¯å’Œå¥å­ä¿¡æ¯çš„å­—å…¸
        """
        return {
            'word': {
                'text': self.word,
                'definition': self.word_definition,
                'pronunciation': self.word_pronunciation,
                'example': self.word_example
            },
            'sentence': {
                'text': self.sentence,
                'author': self.sentence_author,
                'tags': self.sentence_tags
            }
        }